
## Q0. 基础实验环境

(1) 操作系统:CentOS6.5 VMWare虚拟机环境，两个节点均安装`VMwareTools`，通过虚拟机`/mnt/hgfs`挂载宿主机。

```shell
➜  examUse  tree ./
./
├── elephaht_examhos
│   ├── Enmoedu_Hadoop_CentOS_6.5_CDH_5.6.vmdk
│   └── Enmoedu_Hadoop_CentOS_6.5_CDH_5.6.vmx
└── monkey_exam
    ├── Enmoedu_Hadoop_CentOS_6.5_CDH_5.6.vmdk
    └── Enmoedu_Hadoop_CentOS_6.5_CDH_5.6.vmx
```

(2) 局域网环境，网卡设置为桥接模式，主从两节点(elephant/monkey)

```shell
[enmoedu@bogon ~]$ hostname
elephant
[enmoedu@bogon ~]$ ifconfig | grep 10
          inet addr:10.8.2.157  Bcast:10.8.2.255  Mask:255.255.255.0
          collisions:0 txqueuelen:1000
          RX packets:10 errors:0 dropped:0 overruns:0 frame:0
          TX packets:10 errors:0 dropped:0 overruns:0 carrier:0

[enmoedu@bogon ~]$ hostname
monkey
[enmoedu@bogon ~]$ ifconfig | grep 10
          inet addr:10.8.2.168  Bcast:10.8.2.255  Mask:255.255.255.0
          collisions:0 txqueuelen:1000
```

(3)设置关闭防火墙和SELinux

```shell
# change to root user
[root@elephant enmoedu]# service iptables stop
iptables: Setting chains to policy ACCEPT: filter          [  OK  ]
iptables: Flushing firewall rules:                         [  OK  ]
iptables: Unloading modules:                               [  OK  ]

# edit selinux configure file
[root@elephant enmoedu]# vim /etc/selinux/config

# change `enforcing` to `disabled`
SELINUX=disabled

# shutdown selinux forever
[root@monkey enmoedu]# setenforce 0

# deny iptables restart when system reboot
[root@monkey enmoedu]# chkconfig iptables off

# check iptables setting
[root@monkey enmoedu]# chkconfig --list | grep iptables
iptables       	0:关闭	1:关闭	2:关闭	3:关闭	4:关闭	5:关闭	6:关闭
[root@monkey enmoedu]#
```
(4) 基于阶段一搭建成功的实验环境，主从节点均已配置安装`JDK`环境以及`CDH`套装中安装了`YARN/HDFS`(但安装服务都处于`Bad Health`状态)。

```shell
[root@monkey /]# hostname
monkey
[root@monkey /]# java -version
java version "1.7.0_67"
Java(TM) SE Runtime Environment (build 1.7.0_67-b01)
Java HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode)
[root@monkey /]# chkconfig --list | grep cloud
cloudera-scm-agent	0:关闭	1:关闭	2:关闭	3:启用	4:启用	5:启用	6:关闭
###################split line###############################
[root@elephant /]# hostname
elephant
[root@elephant /]# java -version
java version "1.7.0_67"
Java(TM) SE Runtime Environment (build 1.7.0_67-b01)
Java HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode)
[root@elephant /]# chkconfig --list | grep cloud
cloudera-scm-agent	0:关闭	1:关闭	2:关闭	3:启用	4:启用	5:启用	6:关闭
cloudera-scm-server	0:关闭	1:关闭	2:关闭	3:启用	4:启用	5:启用	6:关闭
cloudera-scm-server-db	0:关闭	1:关闭	2:关闭	3:启用	4:启用	5:启用	6:关闭
```

查看`CM`安装好的`HDFS状态`，访问`http://elephant:50070`

![](/Users/diggzhang/code/big_data_on_my_way/exam_week3/imgs/qa00-elephant-50070-dfshealth-html.png)

----

## Q1. 分布式文件系统有很多产品，我们学习了Hadoop的分布式文件系统HDFS：列举2个以上其它分布式文件系统产品

1. `Haystack` FaceBook一个为高效存储和检索billion级别图片而优化定制的对象存储系统。
2. `TFS` （Taobao File System）是淘宝自主开发的一个分布式文件系统，适用于海量小文件存储。
3. `GridFS` GridFS是MongoDB的一个内置功能，它提供一组文件操作的API以利用MongoDB存储文件，GridFS的基本原理是将文件保存在两个Collection中，一个保存文件索引，一个保存文件内容，文件内容按一定大小分成若干块，每一块存在一个Document中，这种方法不仅提供了文件存储，还提供了对文件相关的一些附加属性（比如MD5值，文件名等等）的存储。我们在生产环境和分析环境部署使用了`MongoDB`，以`MongoDB3.2`版本为例，为mongo本身提供效率的并不是依赖GridFS，而是内存，`MongoDB`会默认将数据索引加载到内存中，从而提高查询效率。
4. `Ceph` `RedHat`为其撰写的标语是"适用于 PB 级数据存储的下一代平台"


----

## Q2. 如何查看HDFS块大小，请列举将块大小设置成该值的3点原因，（看google gfs论文）

从` /etc/hadoop/conf/hdfs-site.xml `可以看到HDFS的块大小

```shell
[enmoedu@elephant Desktop]$ cat /etc/hadoop/conf/hdfs-site.xml

...
<property>
    <name>dfs.blocksize</name>
    <value>134217728</value>  //128M
</property>
...
```

`dfs.blocksize`配置项代表着`hdfs`的块大小。在《Google File System》中定义`Chunk`大小为`64M`，这个值和配置文件中的`128M`不符，经查证原来是在`Hadoop2.X`版本中默认大小提升到了`128M`，之前的版本是`64M`。

![](/Users/diggzhang/code/big_data_on_my_way/exam_week3/imgs/qa02_block_size.png)

为什么将块大小设置的这么大？有以下几点原因：

> 摘自《Google File System》 设计概述 元数据  Chunk尺寸

1. 减少了客户端和Master节点通讯的需求,因为只需要一次和Mater节点的通信就可以获取Chunk的位置信息,之后就可以对同一个Chunk进行多次的读写操作。这种方式对降低系统的工作负载来说效果显著,因为大数据应用程序通常是连续读写大文件。但即使是小规模的随机读取,采用较大的Chunk尺寸也带来明显的好处,客户端可以轻松的缓存一个数TB的工作数据集所有的Chunk位置信息;
2. 采用较大的 Chunk 尺寸,客户端能够对一个块进行多次操作,这样就可以通过与 Chunk 服务器保持较长时间的 TCP 连接来减少网络负载;
3. 选用较大的 Chunk 尺寸减少了 Master 节点需要保存的元数据的数量。这就允许我们把元数据全部放在内存中。


---

## Q3. 将/etc/passwd文件上传到hdfs,并将该文件的元数据信息条目截图

(1) 将文件上传到`HDFS`

```shell
[enmoedu@elephant ~]$ hadoop fs -put /etc/passwd .
[enmoedu@elephant ~]$ hadoop fs -ls
Found 1 items
-rw-r--r--   3 enmoedu enmoedu       2616 2017-04-13 16:16 passwd
```

(2) 查看文件的元数据目录

从`/etc/hadoop/conf/hdfs-site.xml`中获取`dfs.namenode.name.dir`的`value`信息，`value`下就是`元数据`存放地址。

```shell
[root@elephant current]# head -n 10 /etc/hadoop/conf/hdfs-site.xml
<?xml version="1.0" encoding="UTF-8"?>

<!--Autogenerated by Cloudera Manager-->
<configuration>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///dfs/nn</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address</name>
[root@elephant current]# pwd
/dfs/nn/current
[root@elephant current]# ls
edits_0000000000000000001-0000000000000000027   fsimage_0000000000000001018
......
```

在元数据目录下非`md5`后缀文件名结尾的`edists* / fsimage* `都是`HDFS`的元数据信息:

- `fsimage*` 只负责供给查询业务元数据
- `edits*` 只负责记录对元数据更改的事务

每次namenode进程重启，都会融合fsimage和edits，形成新的`fsimage`。

(3) 实际操作截图

*在实际操作的时候，可能因为跟老师视频的实验环境不一致，有些命令执行效果不一样，但在`hdfs上传文件然后查看dfs里的元数据信息`这一流程基础操作应该差不了多少，所以按照搜索来的方法实现本次实验：*


确认安装`CDH`时候已经创建`hdfs`用户，准备好需要上传到hdfs的文件:

```shell
[root@elephant enmoedu]# cat /etc/passwd | grep hdfs
hdfs:x:493:489:Hadoop HDFS:/var/lib/hadoop-hdfs:/bin/bash

[root@elephant enmoedu]# ll -h /etc/passwd
-rw-r--r-- 1 root root 2.6K 4月   7 00:17 /etc/passwd
```

![](/Users/diggzhang/code/big_data_on_my_way/exam_week3/imgs/qa02_check_passwd_file.png)

找到`dfs.namenode.name.dir`，也就是namenode元数据的目录:

![](/Users/diggzhang/code/big_data_on_my_way/exam_week3/imgs/qa03_find_namenode_dir.png)

相应的找到`datanode`的元数据,主节点负责datanode，从节点负责datanode:

![](/Users/diggzhang/code/big_data_on_my_way/exam_week3/imgs/qa03_name_data_node_info.png)

---

## Q4. HDFS通过什么机制保护数据？通过什么机制保护元数据？

(1) HDFS通过什么机制保护数据： 粗略描述，HDFS默认会为数据设置三个副本，其中两个副本放在同机架，另一个副本放在不同机架，当某个副本发生故障，就从其余副本备份中拷贝。这种设计，感觉上有点类似`RAID5`。

(2) 通过什么机制保护元数据

## Q5. 将任意文件上传到`HDFS`，请问此时该文件的元数据信息的具体位置。请找出HDFS路径，并dump元数据信息进行查看？

## Q6. 执行任意`MapReduce`程序，并从执行开始描述`YARN`以及`MapReduce`组建各个角色工作原理？
